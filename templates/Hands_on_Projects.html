<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/static/css/Hands_on_Projects.css">
    <title>Document</title>
</head>
<body>
    <header>
        <nav class="navbar">
            <div class="logo">
                <a href="/"><h1 id="logo">EnduraMind</h1></a>
            </div>
            <ul class="nav-links">
                <li><a href="/features">Features</a></li>
                <li><a href="/courses">Courses</a></li>
                <li><a href="/community">Community</a></li>
                <li><a href="/about">About Us</a></li>
                <li><a href="/contact">Contact</a></li>
            </ul>
            <div class="auth-buttons">
                <div id="g_id_onload" data-client_id="489201882672-elcgm6oqbnk8lb2stglrr7m7o0kmkqpl.apps.googleusercontent.com" data-callback="handleCredentialResponse"></div>
                <div class="g_id_signin" data-type="standard"></div>
            </div>   
        </nav>
    </header>

    <div class="engage">
        <h1>Explore The world Of Artificial Intelligence</h1>
        <p>Here is the list of examples of what you will learn in this platform</p>
    </div>

    <div class="Models">
        <form id="searchForm" action="/choose_model" method="post">
            <input type="text" id="searchInput" name="selected_model" placeholder="Search...">
            <ul id="suggestions"></ul>
            <button type="submit">Confirm</button>
        </form>
    
        {% if selected_model %}
            {% if selected_model == 'Gemini (Natural Language Processing)' %}
            <h1>Chatbot here!</h1>
            <div class="chat-container" id="chatbox">
                <div class="bot message">Bot: Sin o **gwapo**?</div>
            </div>
            <input type="text" id="userInput" placeholder="Type a message..." />
            <button onclick="sendMessage()">Send</button>

            <div class="description">
                <div class="description-header">
                    <h1>Gemini: Revolutionizing Natural Language Processing</h1>
                    <p class="tagline">"Empowering machines to communicate, understand, and connect."</p>
                </div>
                <div class="description-content">
                    <p>
                        Gemini is a state-of-the-art natural language processing (NLP) model designed to bring your AI projects to life. Whether you're building intelligent chatbots, creating personalized virtual assistants, or analyzing text data, Gemini offers unparalleled capabilities. 
                    </p>
                    <ul class="features-list">
                        <li><strong>Contextual Understanding:</strong> Gemini can comprehend the nuances of human language, including slang, emotions, and intent.</li>
                        <li><strong>Conversational AI:</strong> Create chatbots that feel more human and understand complex conversations.</li>
                        <li><strong>Multi-Language Support:</strong> Work with text in multiple languages, breaking down communication barriers.</li>
                        <li><strong>Sentiment Analysis:</strong> Analyze customer feedback, reviews, and social media posts with ease.</li>
                        <li><strong>Text Generation:</strong> Generate creative and contextually accurate responses, summaries, or even stories.</li>
                    </ul>
                    <p>
                        Gemini is your gateway to transforming ideas into reality. Whether you're a developer, researcher, or entrepreneur, this model adapts to your unique requirements.
                    </p>
                </div>
                <div class="description-cta">
                    <a href="https://support.google.com/gemini/answer/13278668?hl=en"  class="cta-button">Learn More</a>
                    <a href="https://gemini.google.com/app" class="cta-button secondary">Try Gemini Now</a>
                </div>
            </div>
            {% elif selected_model == 'Deep_seekR1' %}
            <h1>Deep_seekR1</h1>
            <div class="chat-container" id="chatbox">
                <div class="bot message">Bot: Sin o **gwapo**?</div>
            </div>
            <input type="text" id="userInput" placeholder="Type a message..." />
            <button onclick="sendMessage()">Send</button>
            
            
            {% elif selected_model == 'ResNet-50 (Image Classification)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>ResNet-50: Redefining Image Classification</h1>
                        <p class="tagline">"Deep Residual Learning for image recognition at scale."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            ResNet-50 is a cutting-edge convolutional neural network (CNN) architecture built to achieve exceptional accuracy in image classification tasks. Its deep residual learning framework addresses the challenge of vanishing gradients, enabling the network to learn deeper and more complex features.
                        </p>
                        <ul class="features-list">
                            <li><strong>High Accuracy:</strong> Leverages 50-layer residual blocks for precise feature extraction.</li>
                            <li><strong>Transfer Learning:</strong> Easily fine-tune for custom datasets and specific classification tasks.</li>
                            <li><strong>Scalability:</strong> Performs well across small to large-scale datasets.</li>
                            <li><strong>Real-World Applications:</strong> Used in autonomous vehicles, healthcare, e-commerce, and more.</li>
                            <li><strong>Performance:</strong> Optimized for efficient training and inference on GPUs.</li>
                        </ul>
                        <p>
                            ResNet-50 has revolutionized the way deep learning tackles image recognition, making it the go-to model for professionals and researchers alike. Whether you're working with CIFAR-10 or the Stanford Cars dataset, ResNet-50 adapts seamlessly to meet your needs.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://arxiv.org/abs/1512.03385" class="cta-button">Learn More</a>
                        <a href="https://github.com/Sudhandar/ResNet-50-model" class="cta-button secondary">Try ResNet-50 Now</a>
                    </div>
                </div>

            
                {% elif selected_model == 'YOLOv11 (Object Detection)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>YOLOv11: The Next Generation of Object Detection</h1>
                        <p class="tagline">"Real-time object detection with unmatched precision and speed."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            YOLOv11 represents the latest advancements in object detection technology. Designed to be fast, efficient, and highly accurate, YOLOv11 continues the YOLO tradition of real-time performance while introducing innovative features for enhanced object detection capabilities.
                        </p>
                        <ul class="features-list">
                            <li><strong>Real-Time Detection:</strong> Achieves lightning-fast inference speeds while maintaining high accuracy.</li>
                            <li><strong>Enhanced Precision:</strong> Introduces new algorithms for better localization and classification.</li>
                            <li><strong>Lightweight Design:</strong> Optimized for deployment on edge devices, making it ideal for IoT applications.</li>
                            <li><strong>Multi-Scale Detection:</strong> Detects objects at various scales within a single frame.</li>
                            <li><strong>Wide Applications:</strong> Used in surveillance, autonomous vehicles, medical imaging, and more.</li>
                        </ul>
                        <p>
                            YOLOv11 is your ultimate tool for object detection tasks, offering unparalleled performance and flexibility. Whether you're working on real-time applications or complex datasets, YOLOv11 delivers results that exceed expectations.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://docs.ultralytics.com/" class="cta-button">Learn More</a>
                        <a href="https://github.com/ultralytics/ultralytics" class="cta-button secondary">Try YOLOv11 Now</a>
                    </div>
                </div>

            
            {% elif selected_model == 'Mask R-CNN (Instance Segmentation)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>Mask R-CNN: Advanced Instance Segmentation</h1>
                        <p class="tagline">"Pixel-level object detection and segmentation with precision."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            Mask R-CNN is a state-of-the-art model for instance segmentation, combining object detection and pixel-wise segmentation to identify and segment individual objects in an image. Its two-stage architecture builds on Faster R-CNN, adding a fully convolutional network for precise mask prediction.
                        </p>
                        <ul class="features-list">
                            <li><strong>Instance Segmentation:</strong> Provides pixel-level masks for each detected object.</li>
                            <li><strong>Two-Stage Architecture:</strong> Combines region proposal networks with segmentation head for high accuracy.</li>
                            <li><strong>Scalable and Flexible:</strong> Performs well across various domains, including medical imaging, autonomous driving, and more.</li>
                            <li><strong>Mask Prediction:</strong> Uses ROIAlign for precise mask generation at the pixel level.</li>
                            <li><strong>Real-World Applications:</strong> Ideal for tasks requiring both object detection and segmentation.</li>
                        </ul>
                        <p>
                            Mask R-CNN's ability to segment and detect objects at a granular level makes it a preferred choice for tasks requiring detailed scene understanding. From industrial automation to scientific research, it provides the tools to take image analysis to the next level.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://arxiv.org/abs/1703.06870" class="cta-button">Learn More</a>
                        <a href="https://github.com/matterport/Mask_RCNN" class="cta-button secondary">Try Mask R-CNN Now</a>
                    </div>
                </div>
            

            {% elif selected_model == 'Faster R-CNN (Object Detection)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>Faster R-CNN: High-Performance Object Detection</h1>
                        <p class="tagline">"Fast and accurate object detection with region proposal networks."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            Faster R-CNN is a cutting-edge model for object detection, known for its speed and accuracy. It integrates a Region Proposal Network (RPN) with a Fast R-CNN detector, enabling fast object proposals and precise object localization. This architecture allows Faster R-CNN to outperform other object detection models in terms of accuracy and processing speed.
                        </p>
                        <ul class="features-list">
                            <li><strong>Fast and Accurate:</strong> Achieves high accuracy while maintaining rapid processing speeds.</li>
                            <li><strong>Region Proposal Network (RPN):</strong> Automatically generates object proposals without the need for external algorithms.</li>
                            <li><strong>End-to-End Training:</strong> Both RPN and detection networks are trained simultaneously.</li>
                            <li><strong>Versatile:</strong> Suitable for a wide range of object detection applications, from security to retail.</li>
                            <li><strong>Real-Time Performance:</strong> Optimized for real-time object detection with high-speed inference.</li>
                        </ul>
                        <p>
                            Faster R-CNN's combination of speed and precision makes it ideal for a variety of practical applications, from autonomous vehicles to video surveillance. It provides the foundation for building powerful object detection systems that can process images in real time while identifying objects with high accuracy.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://arxiv.org/abs/1506.01497" class="cta-button">Learn More</a>
                        <a href="https://github.com/rbgirshick/py-faster-rcnn" class="cta-button secondary">Try Faster R-CNN Now</a>
                    </div>
                </div>
            
            {% elif selected_model == 'VGG-16 (Image Classification)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>VGG-16: Deep Convolutional Neural Network for Image Classification</h1>
                        <p class="tagline">"Powerful and deep architecture for precise image classification."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            VGG-16 is a deep convolutional neural network (CNN) model, renowned for its simple yet effective architecture. It uses a series of convolutional layers with small receptive fields, followed by fully connected layers. This structure allows VGG-16 to achieve high accuracy in image classification tasks, especially with large datasets like ImageNet.
                        </p>
                        <ul class="features-list">
                            <li><strong>Deep Architecture:</strong> Composed of 16 layers, allowing for powerful feature extraction and learning.</li>
                            <li><strong>High Accuracy:</strong> Known for its high performance on large-scale image classification benchmarks.</li>
                            <li><strong>Simple and Effective:</strong> Uses small 3x3 convolution filters and max-pooling layers.</li>
                            <li><strong>Versatile:</strong> Can be fine-tuned for different image classification tasks.</li>
                            <li><strong>Transfer Learning:</strong> VGG-16’s pretrained weights on large datasets are useful for transfer learning in other tasks.</li>
                        </ul>
                        <p>
                            VGG-16 has proven to be a very effective model for image classification tasks, achieving high accuracy on large-scale datasets. Its straightforward architecture and deep layers make it a reliable choice for many computer vision applications.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://arxiv.org/abs/1409.1556" class="cta-button">Learn More</a>
                        <a href="https://github.com/keras-team/keras-applications/blob/master/keras_applications/vgg16.py" class="cta-button secondary">Try VGG-16 Now</a>
                    </div>
                </div>
            
            {% elif selected_model == 'MobileNetV2 (Lightweight Image Classification)' %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            
                <div class="description">
                    <div class="description-header">
                        <h1>MobileNetV2: Lightweight and Efficient Image Classification</h1>
                        <p class="tagline">"Optimized for mobile devices with excellent accuracy."</p>
                    </div>
                    <div class="description-content">
                        <p>
                            MobileNetV2 is a lightweight and efficient convolutional neural network (CNN) designed specifically for mobile and edge devices. It utilizes an inverted residual structure, where depthwise separable convolutions are combined with linear bottleneck layers to reduce computational cost while maintaining high accuracy for image classification tasks. This model is particularly suited for environments with limited resources, making it ideal for real-time applications on mobile devices.
                        </p>
                        <ul class="features-list">
                            <li><strong>Lightweight Architecture:</strong> Utilizes depthwise separable convolutions and linear bottleneck layers to reduce complexity.</li>
                            <li><strong>Mobile Optimization:</strong> Designed specifically for mobile devices and edge computing, offering high efficiency with low computational cost.</li>
                            <li><strong>High Accuracy:</strong> Despite its compact size, MobileNetV2 achieves competitive performance on standard image classification benchmarks.</li>
                            <li><strong>Real-Time Performance:</strong> Capable of running in real time on resource-constrained devices.</li>
                            <li><strong>Versatile:</strong> Suitable for various computer vision tasks, including object detection and segmentation, when fine-tuned.</li>
                        </ul>
                        <p>
                            MobileNetV2’s efficient architecture makes it an excellent choice for applications that require fast processing on mobile devices or edge hardware. With its balance of speed and accuracy, it is ideal for a range of mobile applications such as augmented reality, autonomous driving, and wearable technology.
                        </p>
                    </div>
                    <div class="description-cta">
                        <a href="https://arxiv.org/abs/1801.04381" class="cta-button">Learn More</a>
                        <a href="https://github.com/tensorflow/models/tree/master/research/slim" class="cta-button secondary">Try MobileNetV2 Now</a>
                    </div>
                </div>
            
            
            {% else %}
                <h2>You selected: {{ selected_model }}</h2>
                <form action="/upload_image" method="post" enctype="multipart/form-data">
                    <input type="hidden" name="selected_model" value="{{ selected_model }}">
                    <input type="file" name="file" accept="image/jpeg, image/png, image/jpg">
                    <button type="submit">Upload Image</button>
                </form>
            {% endif %}
        {% else %}
            <h2>Please select a model</h2>

            

        {% endif %}
    
        {% if request.query_params.message2 %}
            <p>{{ request.query_params.message2 }}</p>
        {% endif %}
    
        {% if message %}
            <img src="{{ message }}" alt="Uploaded image">
        {% endif %}
    </div>
    

      





    <script src="/static/js/Hands_on_Projects.js"></script>
</body>
</html>